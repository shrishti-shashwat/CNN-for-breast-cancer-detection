# -*- coding: utf-8 -*-
"""CNN for Breast Cancer Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1exqZ0O6IP7KKO5m4yFeUaaUzF2mN-JhP

# Step 1: Installation and Setup
"""

!pip install --upgrade pip setuptools

!pip install tensorflow

import tensorflow as tf

print(tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# Step 2: Data Preprocess"""

# Importing dataset from sklearn
from sklearn import datasets, metrics

# Import the dataset
cancer = datasets.load_breast_cancer()

print(cancer.DESCR)

# Selecting dependent and independent variable

# matrix of features / independent variable

x = pd.DataFrame(data = cancer.data, columns=cancer.feature_names)

x.head()

# Selecting dependent variable
y= cancer.target
print(y)

cancer.target_names

"""0 is for malignant and 1 is for benign"""

x.shape, y.shape

# Spliting the dataset in train and test set

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)

x_train.shape, x_test.shape

# feature scaling

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_train.shape, x_test.shape

x_train = x_train.reshape(455, 30, 1)
x_test = x_test.reshape(114, 30, 1)

x_train.shape, x_test.shape

"""Converting the dimension into 2 D

# Step 3: Building the Model
"""

# Defining an object
model = tf.keras.models.Sequential()

# First CNN layer
model.add(tf.keras.layers.Conv1D(filters = 32, kernel_size=2, activation = 'relu', input_shape = (30,1)))

# batch normalization
model.add(tf.keras.layers.BatchNormalization())

# Dropout layer
model.add(tf.keras.layers.Dropout(0.2))

# Second CNN layer
model.add(tf.keras.layers.Conv1D(filters = 64, kernel_size=2, activation = 'relu'))

# batch normalization
model.add(tf.keras.layers.BatchNormalization())

# Dropout layer
model.add(tf.keras.layers.Dropout(0.4))

# flatten layer
model.add(tf.keras.layers.Flatten())

# dense layer
model.add(tf.keras.layers.Dense(units=64, activation ='relu'))

# output layer
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

model.summary()

# Compile model

opt = tf.keras.optimizers.Adam(learning_rate = 0.00005)

model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])

"""# Step 4: Training the model"""

history = model.fit(x_train, y_train, epochs = 50 , validation_data=(x_test, y_test))

"""# Step 5: Model predictions"""

# Get predicted probabilities
y_pred_prob = model.predict(x_test)

# Apply threshold to convert probabilities to class labels (0 or 1)
y_pred = (y_pred_prob > 0.5).astype("int32")

print(y_pred[12]), print(y_test[12])

print(y_pred[10]), print(y_test[10])

cancer.target_names

# confusion matrix
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)

"""Model is predicting total 112 correct values and 2 wrong predictions"""

# Calculating accuracy using confusion matrix
acc_cm = accuracy_score(y_test, y_pred)
print(acc_cm)

"""# Step 6: Learning Curve"""

def learning_curve(history, epoch):

  # training vs validation accuracy
  epoch_range = range(1, epoch+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.title('Model Accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'val'], loc='upper left')
  plt.show()

  # training vs validation loss
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'val'], loc='upper left')
  plt.show()

learning_curve(history, 50)

"""Accuracy is increasing continuosly and validation accuracy first decreases and then it increases continuosly"""

